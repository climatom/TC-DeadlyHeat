#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
This script interpolates WFDEI met data to different latitudes and longitudes
and writes a combined NetCDF file with data at those points, only. 

Each met variables has the dimensions: 
    - id (nloc)
    - time (ntime)
    
And the following "meta" variables are stored
    - latitude (nloc)
    - longitude (nloc)
    - id (nloc)
    
The script uses the output of filter_landfall.py to know where to interpolate
to!
"""
import GeneralFunctions as GF
import TC_Utils as tc
import numpy as np
from netCDF4 import Dataset

# =========================================================================== #
#                                Functions                                    #
# =========================================================================== #

def write_NC(oname,met_vars,latin,lonin,idin,timein,time_units):
    
    """ All the met-vars are 2d; the meta_vars are 1d. met vars input should
    be in dictionary form: {varname: [array,units]} """
    
    mv=-999.999
    ncfile = Dataset(oname,"w")
    ntime,nloc = met_vars[met_vars.keys()[0]][0].shape 
    
    # Create the dimensions 
    ncfile.createDimension('time',ntime)
    ncfile.createDimension('id',nloc)
    
    # Create the coordinate variables
    times = ncfile.createVariable('time',np.float32,dimensions=['time',])
    lats = ncfile.createVariable('lat',np.float32,dimensions=['id',])
    lons = ncfile.createVariable('lon',np.float32,dimensions=['id',]) 
    ids = ncfile.createVariable('id',np.float32,dimensions=['id',])
    
    # Units
    times.units=time_units
    lats.units="degrees_north"
    lons.units="degrees_east"
    ids.units="unique_IBTrACS_identifier"
    
    # Values
    lats[:]=latin
    lons[:]=lonin
    ids[:]=idin
    times[:]=timein
    
    for key, value in met_vars.iteritems():
        
        # Create variable
        v = ncfile.createVariable(key,np.float32,dimensions=\
                                  ['time','id'],\
                                  fill_value = mv)
        
        # Write data to this variable
        v[:,:]=value[0]
        v.units=value[1]
      
    # now close file 
    ncfile.close() 
    return 0
  
# ============================================================================#
#                           Script parameters                                 #
# ============================================================================#

# Input location file. This was generated by running the filter_landfall.py
# script.
# Format is:
# [0] ID; [1] Year [2] jd.dayfrac; [3] lat; [4] lon; [5] grid lat
# [6] grid lon; [7] grid row; [8] grid col; [9] dist between gridpoint and 
# TC landfall coordinate
locfile="/media/gytm3/WD12TB/TropicalCyclones/TC-DeadlyHeat/Data/LandFall.txt"

# Input (WFDEI) file. This is a template that we'll use to take the WFDEI grid
# parameters from 
hifile="/media/gytm3/WD12TB/WATCH3H/Daily/c_HI_1979.nc"

# Output file path
odir="/media/gytm3/WD12TB/TropicalCyclones/TC-DeadlyHeat/Data/"

# Output file name
oname=odir+"TC_met_all.nc"

# Years to iterate between
yr_st=1979
yr_stp=2015

# ============================================================================#
#                                   MAIN                                      #
# ============================================================================#

# Read in the location file
locs=np.loadtxt(locfile,skiprows=1)
# Take the lat, lon, and id: these will be written to the output netCDF file
id_out=locs[:,0]; lat_out=locs[:,5]; lon_out=locs[:,6]

# Read in the netCDF file
hio=Dataset(hifile,"r"); ntime,nrows,ncols=hio.variables["hi"].shape
time_ref=hio.variables["time"]
times=range(ntime); 
rows=locs[:,-3].astype(np.int)
cols=locs[:,-2].astype(np.int)
times=np.arange(ntime)


# Loop over the years 
out_hi=[]
out_tas=[]
out_q=[]
out_p=[]
out_time=[]; delta=0
for yy in range(yr_st,yr_stp+1):
    
    # =========================#
    # Opening files
    # =========================#
    # get heat index file
    hio=Dataset(hifile.replace("1979","%.0f"%yy),"r") 
    ntime,nrows,ncols=hio.variables["hi"].shape
    
    # repeat with tas
    to=Dataset(hifile.replace("c_HI_1979","Tair_%.0f"%yy),"r") 
    
    
    # and with humidity
    qo=Dataset(hifile.replace("c_HI_1979","Qair_%.0f"%yy),"r") 
    
    # and, finally, with sea-level pressure
    po=Dataset(hifile.replace("c_HI_1979","c_Psurf_%.0f"%yy),"r") 
        
    
    # =========================#
    # Reading Data
    # =========================#    
    # Read in one year's data for hi. 
    # Format: rows are days; columns are locations
    out_hi.append(np.row_stack([hio.variables["hi"][ii,:,:][rows,cols].data \
                                for ii in \
                     range(ntime)]))
    
    # repeat for tas
    out_tas.append(np.row_stack([to.variables["Tair"][ii,:,:][rows,cols].data \
                                 for ii in \
                     range(ntime)]))    
    # ...for humidity
    out_q.append(np.row_stack([qo.variables["Qair"][ii,:,:][rows,cols].data \
                               for ii in \
                     range(ntime)]))       
    # ...and for pressure
    out_p.append(np.row_stack([po.variables["PSurf"][ii,:,:][rows,cols].data \
                               for ii in \
                     range(ntime)]))
    
    print "Processed year: %.0f" % yy
  
# ====================================#
# Organising the ouput and writing out
# ====================================# 
# Stack the individual years together
out_hi=np.row_stack(out_hi)
out_tas=np.row_stack(out_tas)    
out_q=np.row_stack(out_q)  
out_p=np.row_stack(out_p)  

# Daily data, since 1979-1-1 00:00:00
out_time=(np.arange(len(out_hi))+0.5)

# Write the NetCDF4 file out
fail=write_NC(oname,\
              {"hi":[out_hi,"degrees_Celsius"],\
               "Tair":[out_tas,"degrees_Celsius"],\
               "Qair":[out_q,"kg/kg"],\
               "PSurf":[out_p,"Pa"]},\
               lat_out,lon_out,id_out,out_time,\
               "days since 1979-1-1 00:00:00")
